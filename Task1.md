# Task 1

## 1.1 随记

1. 数据决定模型的上限，而算法则是让模型无限逼近上限

2. 离散值的预测称为分类（二分类/多分类），连续值的预测称为回归

3. 聚类的实质是分组，有助于更好地了解数据集的内在规律。

4. 根据训练数据的标记与否，可以分为监督学习/无监督学习，前者主要做分类和回归，后者主要做聚类

5. 泛化能力指模型在测试数据上的表现情况，而非训练数据

6. 归纳：从特殊到一般（从基础原理中总结规律），演绎：从基础定理推导具体状况

7.  “若有多个假设与观察一致,则选最简单的那个”，即选择更平滑的训练模型

8. 过拟合：对训练数据学习过于强大（权重过高），将样本局部的特性视为一般性质。欠拟合则是权重过低，无法就训练数据给出正确结果

9. 模型选择原则：泛化误差最小且尽量平滑简单。但不实际测试无法得到泛化误差，因此，就可以不全部利用训练数据，而是选择性利用一部分，另一部分“视为”训练数据。实现既要训练又要测试

   

   | 留出法     | 要注意样本划分问题                                      |
   | ---------- | ------------------------------------------------------- |
   | 交叉验证法 | 先划分为不重复的K个部分，每次随机选取K-1个训练，重复K次 |
   | 自助法     | 每次随机挑选若干个数据集，训练后放回，重复若干次        |



第一二章比较简单，算是常识性的概念引入，但我对数学推导仍存在问题，稍后补充